{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "charsiu_demo.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zxKOeyTROc2"
      },
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install datasets transformers\n",
        "!pip install g2p_en praatio librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIROcsj7Rv4g",
        "outputId": "8488328f-f216-4a60-8adf-da7bc0d75d43"
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, expanduser\n",
        "\n",
        "os.chdir(expanduser(\"~\"))\n",
        "charsiu_dir = 'charsiu'\n",
        "if exists(charsiu_dir):\n",
        "  !rm -rf /root/charsiu\n",
        "if not exists(charsiu_dir):\n",
        "  ! git clone -b development https://github.com/lingjzhu/$charsiu_dir\n",
        "  ! cd charsiu && git checkout && cd -\n",
        "  \n",
        "os.chdir(charsiu_dir)    "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'charsiu'...\n",
            "remote: Enumerating objects: 294, done.\u001b[K\n",
            "remote: Counting objects: 100% (294/294), done.\u001b[K\n",
            "remote: Compressing objects: 100% (251/251), done.\u001b[K\n",
            "remote: Total 294 (delta 137), reused 135 (delta 38), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (294/294), 505.20 KiB | 2.05 MiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n",
            "Your branch is up to date with 'origin/development'.\n",
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmHNb4OxRVD8"
      },
      "source": [
        "import sys\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append('src/')\n",
        "#sys.path.insert(0,'src')\n",
        "from Charsiu import charsiu_forced_aligner, charsiu_attention_aligner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2wZBRx_WOfv"
      },
      "source": [
        "timit = load_dataset('timit_asr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBzpi5mSjiyL",
        "outputId": "325f577f-0624-43de-9154-3be12abc2c1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load data\n",
        "sample = timit['train'][0]\n",
        "text = sample['text']\n",
        "audio_path = sample['file']\n",
        "print('Text transcription:%s'%(text))\n",
        "print('Audio path: %s'%audio_path)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text transcription:Would such an act of refusal be useful?\n",
            "Audio path: /root/.cache/huggingface/datasets/downloads/extracted/404950a46da14eac65eb4e2a8317b1372fb3971d980d91d5d5b221275b1fd7e0/data/TRAIN/DR4/MMDM0/SI681.WAV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7paWfYdROc5",
        "outputId": "d494e91a-863d-4ca5-f9bb-e8c3160d3543"
      },
      "source": [
        "# initialize model\n",
        "charsiu = charsiu_forced_aligner(aligner='charsiu/en_w2v2_fc_10ms')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:341: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYUK0SUKxtt_"
      },
      "source": [
        "Forced alignment with a neural forced alignment model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHW92QgDROc4"
      },
      "source": [
        "alignment = charsiu.align(audio=audio_path,text=text)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCmbdfpzXrQ3",
        "outputId": "e2017f28-4fc1-4394-e21e-47771a59d740"
      },
      "source": [
        "print(alignment)\n",
        "print('\\n Ground Truth \\n')\n",
        "print([(s/16000,e/16000,p) for s,e,p in zip(sample['phonetic_detail']['start'],sample['phonetic_detail']['stop'],sample['phonetic_detail']['utterance'])])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.0, 0.08, '[SIL]'), (0.08, 0.15, 'W'), (0.15, 0.19, 'UH'), (0.19, 0.24, 'D'), (0.24, 0.38, 'S'), (0.38, 0.46, 'AH'), (0.46, 0.58, 'CH'), (0.58, 0.6, 'AE'), (0.6, 0.68, 'N'), (0.68, 0.82, 'AE'), (0.82, 0.93, 'K'), (0.93, 0.99, 'T'), (0.99, 1.04, 'AH'), (1.04, 1.13, 'V'), (1.13, 1.17, 'R'), (1.17, 1.22, 'AH'), (1.22, 1.33, 'F'), (1.33, 1.41, 'Y'), (1.41, 1.48, 'UW'), (1.48, 1.53, 'Z'), (1.53, 1.62, 'AH'), (1.62, 1.68, 'L'), (1.68, 1.78, 'B'), (1.78, 1.88, 'IY'), (1.88, 1.99, 'Y'), (1.99, 2.08, 'UW'), (2.08, 2.13, 'S'), (2.13, 2.23, 'F'), (2.23, 2.27, 'AH'), (2.27, 2.47, 'L'), (2.47, 2.48, '[SIL]')]\n",
            "\n",
            " Ground Truth \n",
            "\n",
            "[(0.0, 0.1225, 'h#'), (0.1225, 0.154125, 'w'), (0.154125, 0.2175, 'ix'), (0.2175, 0.25, 'dcl'), (0.25, 0.3725, 's'), (0.3725, 0.4675, 'ah'), (0.4675, 0.4925, 'tcl'), (0.4925, 0.5875, 'ch'), (0.5875, 0.6225, 'ix'), (0.6225, 0.6675, 'n'), (0.6675, 0.8425, 'ae'), (0.8425, 0.98, 'kcl'), (0.98, 0.9925, 't'), (0.9925, 1.0575, 'ix'), (1.0575, 1.1435625, 'v'), (1.1435625, 1.180125, 'r'), (1.180125, 1.2175, 'ix'), (1.2175, 1.3576875, 'f'), (1.3576875, 1.40725, 'y'), (1.40725, 1.5025, 'ux'), (1.5025, 1.574375, 'zh'), (1.574375, 1.6925, 'el'), (1.6925, 1.76, 'bcl'), (1.76, 1.785, 'b'), (1.785, 1.8825, 'iy'), (1.8825, 1.9895, 'y'), (1.9895, 2.0775, 'ux'), (2.0775, 2.165, 's'), (2.165, 2.248, 'f'), (2.248, 2.3575, 'el'), (2.3575, 2.495, 'h#')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJkF2z91ROc5",
        "outputId": "1b2c838d-b794-489e-aacd-7cccb149fb81"
      },
      "source": [
        "# save alignment\n",
        "charsiu.serve(audio=audio_path,text=text,save_to='./local/sample.TextGrid')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alignment output has been saved to ./local/sample.TextGrid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swtLnWRlvTdr"
      },
      "source": [
        "Forced Alignment with An Attention Alignment Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mKL4RzfuP2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "84b03dae-bc59-4a54-8b1d-58f303bbed55"
      },
      "source": [
        "charsiu = charsiu_attention_aligner('charsiu/en_w2v2_fs_10ms')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:341: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-435aab073390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcharsiu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcharsiu_attention_aligner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'charsiu/en_w2v2_fs_10ms'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/root/charsiu/src/Charsiu.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, aligner, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maligner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2ForAttentionAlignment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_freeze_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'charsiu_attention_aligner' object has no attribute '_freeze_model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHhEVix-ugEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c8bb5e-7ad9-40e6-baed-98d35de143a0"
      },
      "source": [
        "# load data\n",
        "sample = timit['train'][0]\n",
        "text = sample['text']\n",
        "audio_path = sample['file']\n",
        "print('Text transcription:%s'%(text))\n",
        "print('Audio path: %s'%audio_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text transcription:Would such an act of refusal be useful?\n",
            "Phone transcription: ['W', 'UH', 'D', ' ', 'S', 'AH', 'CH', ' ', 'AE', 'N', ' ', 'AE', 'K', 'T', ' ', 'AH', 'V', ' ', 'R', 'AH', 'F', 'Y', 'UW', 'Z', 'AH', 'L', ' ', 'B', 'IY', ' ', 'Y', 'UW', 'S', 'F', 'AH', 'L', ' ', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-SpQfeIvnBu"
      },
      "source": [
        "alignment = charsiu.align(audio=audio_path,text=text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbbV0gpuvJW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98d30f2-3fee-4c4b-acad-e0dc2cf73ad6"
      },
      "source": [
        "print(alignment)\n",
        "print('\\n Ground Truth \\n')\n",
        "print([(s/16000,e/16000,p) for s,e,p in zip(sample['phonetic_detail']['start'],sample['phonetic_detail']['stop'],sample['phonetic_detail']['utterance'])])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.0, 0.08, '[SIL]'), (0.08, 0.15, 'W'), (0.15, 0.19, 'UH'), (0.19, 0.24, 'D'), (0.24, 0.38, 'S'), (0.38, 0.46, 'AH'), (0.46, 0.58, 'CH'), (0.58, 0.6, 'AE'), (0.6, 0.68, 'N'), (0.68, 0.82, 'AE'), (0.82, 0.93, 'K'), (0.93, 0.99, 'T'), (0.99, 1.04, 'AH'), (1.04, 1.13, 'V'), (1.13, 1.17, 'R'), (1.17, 1.22, 'AH'), (1.22, 1.33, 'F'), (1.33, 1.41, 'Y'), (1.41, 1.48, 'UW'), (1.48, 1.53, 'Z'), (1.53, 1.62, 'AH'), (1.62, 1.68, 'L'), (1.68, 1.78, 'B'), (1.78, 1.88, 'IY'), (1.88, 1.99, 'Y'), (1.99, 2.08, 'UW'), (2.08, 2.13, 'S'), (2.13, 2.23, 'F'), (2.23, 2.27, 'AH'), (2.27, 2.47, 'L'), (2.47, 2.48, '[SIL]')]\n",
            "\\n Ground Truth \\n\n",
            "[(0.0, 0.1225, 'h#'), (0.1225, 0.154125, 'w'), (0.154125, 0.2175, 'ix'), (0.2175, 0.25, 'dcl'), (0.25, 0.3725, 's'), (0.3725, 0.4675, 'ah'), (0.4675, 0.4925, 'tcl'), (0.4925, 0.5875, 'ch'), (0.5875, 0.6225, 'ix'), (0.6225, 0.6675, 'n'), (0.6675, 0.8425, 'ae'), (0.8425, 0.98, 'kcl'), (0.98, 0.9925, 't'), (0.9925, 1.0575, 'ix'), (1.0575, 1.1435625, 'v'), (1.1435625, 1.180125, 'r'), (1.180125, 1.2175, 'ix'), (1.2175, 1.3576875, 'f'), (1.3576875, 1.40725, 'y'), (1.40725, 1.5025, 'ux'), (1.5025, 1.574375, 'zh'), (1.574375, 1.6925, 'el'), (1.6925, 1.76, 'bcl'), (1.76, 1.785, 'b'), (1.785, 1.8825, 'iy'), (1.8825, 1.9895, 'y'), (1.9895, 2.0775, 'ux'), (2.0775, 2.165, 's'), (2.165, 2.248, 'f'), (2.248, 2.3575, 'el'), (2.3575, 2.495, 'h#')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_Y9eH5KlO4r"
      },
      "source": [
        "charsiu.serve(audio=audio_path,text=text,save_to='./local/sample.TextGrid')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}